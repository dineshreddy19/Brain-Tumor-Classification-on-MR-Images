{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hybrid-tonight",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bt.data import *\n",
    "import torch.nn as nn\n",
    "from bt.models import *\n",
    "from bt.utils import *\n",
    "from torchvision import transforms\n",
    "import torchvision.utils as vutils\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from torchvision.models import inception_v3, resnet50, vgg16, vgg16_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regulation-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_classes = 3\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "lr = 3e-4\n",
    "\n",
    "num_workers = 4\n",
    "\n",
    "image_size = (224, 224)\n",
    "\n",
    "class_names = ['Glioma', 'Meningioma', 'Pituitary']\n",
    "\n",
    "images_dir = 'data/'\n",
    "model_dir = 'models/'\n",
    "\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(columns=['model', 'accuracy', 'loss', 'precision_class_wise', 'precision_avg', 'recall_class_wise', 'recall_avg', 'f1_class_wise', 'f1_avg'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "departmental-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageFolder(root=images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "powerful-designation",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "loved-burlington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "\n",
      "\n",
      "Training the model\n",
      "Epoch:  1  batch:      1 [     1/77]  Loss: 1.127039  Accuracy: 53.125000%\n",
      "Epoch:  1  batch:      3 [     3/77]  Loss: 1.376617  Accuracy: 48.958333%\n",
      "Epoch:  1  batch:      5 [     5/77]  Loss: 1.302411  Accuracy: 51.875000%\n",
      "Epoch:  1  batch:      7 [     7/77]  Loss: 1.027431  Accuracy: 52.678571%\n",
      "Epoch:  1  batch:      9 [     9/77]  Loss: 0.863523  Accuracy: 54.166667%\n",
      "Epoch:  1  batch:     11 [    11/77]  Loss: 0.753767  Accuracy: 57.386364%\n",
      "Epoch:  1  batch:     13 [    13/77]  Loss: 1.042505  Accuracy: 59.134615%\n",
      "Epoch:  1  batch:     15 [    15/77]  Loss: 0.835389  Accuracy: 60.000000%\n",
      "Epoch:  1  batch:     17 [    17/77]  Loss: 0.688325  Accuracy: 61.213235%\n",
      "Epoch:  1  batch:     19 [    19/77]  Loss: 0.829565  Accuracy: 62.335526%\n",
      "Epoch:  1  batch:     21 [    21/77]  Loss: 0.648516  Accuracy: 62.648810%\n",
      "Epoch:  1  batch:     23 [    23/77]  Loss: 0.929497  Accuracy: 62.907609%\n",
      "Epoch:  1  batch:     25 [    25/77]  Loss: 0.905141  Accuracy: 63.750000%\n",
      "Epoch:  1  batch:     27 [    27/77]  Loss: 0.606309  Accuracy: 64.699074%\n",
      "Epoch:  1  batch:     29 [    29/77]  Loss: 0.798395  Accuracy: 64.331897%\n",
      "Epoch:  1  batch:     31 [    31/77]  Loss: 0.697254  Accuracy: 64.717742%\n",
      "Epoch:  1  batch:     33 [    33/77]  Loss: 0.599392  Accuracy: 65.340909%\n",
      "Epoch:  1  batch:     35 [    35/77]  Loss: 0.583546  Accuracy: 65.892857%\n",
      "Epoch:  1  batch:     37 [    37/77]  Loss: 0.351777  Accuracy: 67.145270%\n",
      "Epoch:  1  batch:     39 [    39/77]  Loss: 0.629555  Accuracy: 67.948718%\n",
      "Epoch:  1  batch:     41 [    41/77]  Loss: 0.558134  Accuracy: 67.759146%\n",
      "Epoch:  1  batch:     43 [    43/77]  Loss: 0.648140  Accuracy: 67.950581%\n",
      "Epoch:  1  batch:     45 [    45/77]  Loss: 0.852996  Accuracy: 67.986111%\n",
      "Epoch:  1  batch:     47 [    47/77]  Loss: 0.678151  Accuracy: 68.218085%\n",
      "Epoch:  1  batch:     49 [    49/77]  Loss: 0.617397  Accuracy: 68.239796%\n",
      "Epoch:  1  batch:     51 [    51/77]  Loss: 0.985529  Accuracy: 67.953431%\n",
      "Epoch:  1  batch:     53 [    53/77]  Loss: 0.586650  Accuracy: 67.629717%\n",
      "Epoch:  1  batch:     55 [    55/77]  Loss: 0.415872  Accuracy: 68.125000%\n",
      "Epoch:  1  batch:     57 [    57/77]  Loss: 0.517348  Accuracy: 68.311404%\n",
      "Epoch:  1  batch:     59 [    59/77]  Loss: 0.431613  Accuracy: 68.432203%\n",
      "Epoch:  1  batch:     61 [    61/77]  Loss: 0.496102  Accuracy: 68.750000%\n",
      "Epoch:  1  batch:     63 [    63/77]  Loss: 0.696807  Accuracy: 69.097222%\n",
      "Epoch:  1  batch:     65 [    65/77]  Loss: 0.546646  Accuracy: 69.519231%\n",
      "Epoch:  1  batch:     67 [    67/77]  Loss: 0.456632  Accuracy: 69.916045%\n",
      "Epoch:  1  batch:     69 [    69/77]  Loss: 0.426245  Accuracy: 70.153986%\n",
      "Epoch:  1  batch:     71 [    71/77]  Loss: 0.464715  Accuracy: 70.158451%\n",
      "Epoch:  1  batch:     73 [    73/77]  Loss: 0.507631  Accuracy: 70.419521%\n",
      "Epoch:  1  batch:     75 [    75/77]  Loss: 0.490254  Accuracy: 70.458333%\n",
      "Epoch:  1  batch:     77 [    77/77]  Loss: 0.617889  Accuracy: 70.008117%\n",
      "Epoch 1 | Training Accuracy: 70.008117% | Training Loss: 0.617889\n",
      "Test accuracy: 1995.000000% | Test Loss: 1.768419\n",
      "Test Metrics: \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Score: 0.6509\n",
      "\n",
      "Classification Report: \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.66      0.78      0.72       251\n",
      "         1.0       0.23      0.77      0.35        43\n",
      "         2.0       0.99      0.53      0.69       319\n",
      "\n",
      "    accuracy                           0.65       613\n",
      "   macro avg       0.63      0.69      0.59       613\n",
      "weighted avg       0.80      0.65      0.68       613\n",
      "\n",
      "\n",
      "Precision Score (Class-Wise): \n",
      "[0.65666667 0.23076923 0.99411765]\n",
      "Average Precision Score: 0.6271845148315737\n",
      "\n",
      "Recall Score (Class-Wise): \n",
      "[0.78486056 0.76744186 0.52978056]\n",
      "Average Recall Score: 0.6940276608324544\n",
      "\n",
      "F1 Score (Class-Wise): \n",
      "[0.71506352 0.35483871 0.69120654]\n",
      "Average F1: 0.5870362581719477\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Training Duration 0.64 minutes\n",
      "GPU memory used : 386715648 kb\n",
      "GPU memory cached : 1572864000 kb\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 2\n",
      "\n",
      "\n",
      "Training the model\n",
      "Epoch:  1  batch:      1 [     1/77]  Loss: 1.476801  Accuracy: 25.000000%\n",
      "Epoch:  1  batch:      3 [     3/77]  Loss: 1.275000  Accuracy: 37.500000%\n",
      "Epoch:  1  batch:      5 [     5/77]  Loss: 1.468804  Accuracy: 41.250000%\n",
      "Epoch:  1  batch:      7 [     7/77]  Loss: 0.991056  Accuracy: 42.857143%\n",
      "Epoch:  1  batch:      9 [     9/77]  Loss: 0.750562  Accuracy: 49.305556%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-71dd4e70fdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# print statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight_decay'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                    \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eps'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                    )\n\u001b[0;32m    121\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\optim\\functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m         \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}\\n')\n",
    "    \n",
    "    model_name = f'resnet50_wo_aug_fold_{fold}' \n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler, collate_fn=plain_transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=plain_transform)\n",
    "    \n",
    "    model = resnet50()\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "    \n",
    "    model = model.to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('\\nTraining the model')\n",
    "    b, test_b = 0, 0\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    test_loss = []\n",
    "    test_corr = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        e_start = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        tst_corr = 0.0\n",
    "\n",
    "        for b, (X_train, y_train) in enumerate(trainloader):\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_pred = model(X_train)\n",
    "            \n",
    "            y_pred = y_pred.view(-1, n_classes)\n",
    "            \n",
    "            loss = criterion(y_pred, y_train)\n",
    "\n",
    "            predicted = torch.argmax(y_pred.data, dim=1).data\n",
    "            batch_corr = (predicted == y_train).sum()\n",
    "            running_accuracy += batch_corr\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if b % int(len(trainloader)/batch_size) == 0:\n",
    "                print(f'Epoch: {epoch+1:2}  batch: {b+1:6} [{b+1:6}/{len(trainloader)}]  Loss: {loss.item():.6f}  Accuracy: {running_accuracy.item()*100/((batch_size) * (b+1)):.6f}%')\n",
    "            \n",
    "        training_losses.append(loss.item())\n",
    "        training_accuracies.append(running_accuracy.item()*100/((batch_size) * (b+1)))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Training Accuracy: {training_accuracies[-1]:.6f}% | Training Loss: {training_losses[-1]:.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        b = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            labels = []\n",
    "            pred = []\n",
    "\n",
    "            new_y = 0.0\n",
    "\n",
    "            # perform test set evaluation batch wise\n",
    "            for b, (X, y) in enumerate(testloader):\n",
    "                b += 1\n",
    "                # set label to use CUDA if available\n",
    "                X, y = X.to(device), y.to(device)\n",
    "   \n",
    "                labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "                # perform forward pass\n",
    "                y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "                # get argmax of predicted values, which is our label\n",
    "                predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "                # append predicted label\n",
    "                pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # calculate loss\n",
    "                loss = criterion(y_val, y)\n",
    "\n",
    "                # increment correct with correcly predicted labels per batch\n",
    "                correct += (predicted == y).sum()\n",
    "\n",
    "            # append correct samples labels and losses\n",
    "            test_corr.append(correct.item()*100/len(testloader))\n",
    "            \n",
    "            test_loss.append(loss.item())\n",
    "                \n",
    "        print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "        labels = torch.Tensor(labels)\n",
    "        pred = torch.Tensor(pred)\n",
    "\n",
    "    print(\"Test Metrics: \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name, 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    end_time = time.time() - start_time    \n",
    "\n",
    "    # print training summary\n",
    "    print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "    print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "    print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_reserved()))\n",
    "\n",
    "    plot_loss(training_losses, test_loss) \n",
    "    plot_accuracy(training_accuracies, test_corr) \n",
    "\n",
    "    torch.save(model.state_dict(), model_dir + '/' + model_name + f'_fold_{fold}.pt')\n",
    "    df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "asian-patient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD 1\n",
      "\n",
      "\n",
      "Training the model\n",
      "Epoch:  1  batch:      1 [     1/1226]  Loss: 0.800937  Accuracy: 50.000000%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-99d3568065fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mrunning_accuracy\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbatch_corr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 2 # generates 7 new images + original image - per image, 4 * 8 = 32 images per batch\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}\\n')\n",
    "    \n",
    "    model_name = f'resnet50_w_aug_fold_{fold}' \n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler, collate_fn=augmentor)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=augmentor)\n",
    "    \n",
    "    testloader_plain = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=plain_transform)\n",
    "    \n",
    "    model = resnet50()\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "    \n",
    "    model = model.to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('\\nTraining the model')\n",
    "    b, test_b = 0, 0\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    test_loss = []\n",
    "    test_corr = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        e_start = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        tst_corr = 0.0\n",
    "\n",
    "        for b, (X_train, y_train) in enumerate(trainloader):\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_pred = model(X_train)\n",
    "            \n",
    "            y_pred = y_pred.view(-1, n_classes)\n",
    "            \n",
    "            loss = criterion(y_pred, y_train)\n",
    "\n",
    "            predicted = torch.argmax(y_pred.data, dim=1).data\n",
    "            batch_corr = (predicted == y_train).sum()\n",
    "            running_accuracy += batch_corr\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if b % int(len(trainloader)/batch_size) == 0:\n",
    "                print(f'Epoch: {epoch+1:2}  batch: {b+1:6} [{b+1:6}/{len(trainloader)}]  Loss: {loss.item():.6f}  Accuracy: {running_accuracy.item()*100/((batch_size * 8) * (b+1)):.6f}%')\n",
    "            \n",
    "        training_losses.append(loss.item())\n",
    "        training_accuracies.append(running_accuracy.item()*100/((batch_size * 8) * (b+1)))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Training Accuracy: {training_accuracies[-1]:.6f}% | Training Loss: {training_losses[-1]:.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        b = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            labels = []\n",
    "            pred = []\n",
    "\n",
    "            new_y = 0.0\n",
    "\n",
    "            # perform test set evaluation batch wise\n",
    "            for b, (X, y) in enumerate(testloader):\n",
    "                b += 1\n",
    "                # set label to use CUDA if available\n",
    "                X, y = X.to(device), y.to(device)\n",
    "   \n",
    "                labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "                # perform forward pass\n",
    "                y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "                # get argmax of predicted values, which is our label\n",
    "                predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "                # append predicted label\n",
    "                pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # calculate loss\n",
    "                loss = criterion(y_val, y)\n",
    "\n",
    "                # increment correct with correcly predicted labels per batch\n",
    "                correct += (predicted == y).sum()\n",
    "\n",
    "            # append correct samples labels and losses\n",
    "            test_corr.append(correct.item()*100/len(testloader))\n",
    "            \n",
    "            test_loss.append(loss.item())\n",
    "                \n",
    "        print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "        labels = torch.Tensor(labels)\n",
    "        pred = torch.Tensor(pred)\n",
    "\n",
    "    print(\"Test Metrics: \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name, 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "\n",
    "    print('Testing - without augmentation')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        labels = []\n",
    "        pred = []\n",
    "\n",
    "        new_y = 0.0\n",
    "\n",
    "        # perform test set evaluation batch wise\n",
    "        for b, (X, y) in enumerate(testloader_plain):\n",
    "            b += 1\n",
    "            # set label to use CUDA if available\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "            # perform forward pass\n",
    "            y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "            # get argmax of predicted values, which is our label\n",
    "            predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "            # append predicted label\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(y_val, y)\n",
    "\n",
    "            # increment correct with correcly predicted labels per batch\n",
    "            correct += (predicted == y).sum()\n",
    "\n",
    "        # append correct samples labels and losses\n",
    "        test_corr.append(correct.item()*100/len(testloader_plain))\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "    print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "    labels = torch.Tensor(labels)\n",
    "    pred = torch.Tensor(pred)\n",
    "    \n",
    "    print(\"Test Metrics: \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name + '_test_plain', 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    "    end_time = time.time() - start_time    \n",
    "\n",
    "    # print training summary\n",
    "    print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "    print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "    print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_reserved()))\n",
    "\n",
    "    plot_loss(training_losses, test_loss) \n",
    "    plot_accuracy(training_accuracies, test_corr) \n",
    "\n",
    "    torch.save(model.state_dict(), model_dir + '/' + model_name + f'_fold_{fold}.pt')\n",
    "    df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-graduation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}\\n')\n",
    "    \n",
    "    model_name = f'resnet50_frozen_wo_aug_fold_{fold}' \n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler, collate_fn=plain_transform)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=plain_transform)\n",
    "    \n",
    "    model = resnet50()\n",
    "    \n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "    \n",
    "    for params in model.fc.parameters():\n",
    "        params.requires_grad = True\n",
    "    \n",
    "    model = model.to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('\\nTraining the model')\n",
    "    b, test_b = 0, 0\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    test_loss = []\n",
    "    test_corr = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        e_start = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        tst_corr = 0.0\n",
    "\n",
    "        for b, (X_train, y_train) in enumerate(trainloader):\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_pred = model(X_train)\n",
    "            \n",
    "            y_pred = y_pred.view(-1, n_classes)\n",
    "            \n",
    "            loss = criterion(y_pred, y_train)\n",
    "\n",
    "            predicted = torch.argmax(y_pred.data, dim=1).data\n",
    "            batch_corr = (predicted == y_train).sum()\n",
    "            running_accuracy += batch_corr\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if b % int(len(trainloader)/batch_size) == 0:\n",
    "                print(f'Epoch: {epoch+1:2}  batch: {b+1:6} [{b+1:6}/{len(trainloader)}]  Loss: {loss.item():.6f}  Accuracy: {running_accuracy.item()*100/((batch_size) * (b+1)):.6f}%')\n",
    "            \n",
    "        training_losses.append(loss.item())\n",
    "        training_accuracies.append(running_accuracy.item()*100/((batch_size) * (b+1)))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Training Accuracy: {training_accuracies[-1]:.6f}% | Training Loss: {training_losses[-1]:.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        b = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            labels = []\n",
    "            pred = []\n",
    "\n",
    "            new_y = 0.0\n",
    "\n",
    "            # perform test set evaluation batch wise\n",
    "            for b, (X, y) in enumerate(testloader):\n",
    "                b += 1\n",
    "                # set label to use CUDA if available\n",
    "                X, y = X.to(device), y.to(device)\n",
    "   \n",
    "                labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "                # perform forward pass\n",
    "                y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "                # get argmax of predicted values, which is our label\n",
    "                predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "                # append predicted label\n",
    "                pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # calculate loss\n",
    "                loss = criterion(y_val, y)\n",
    "\n",
    "                # increment correct with correcly predicted labels per batch\n",
    "                correct += (predicted == y).sum()\n",
    "\n",
    "            # append correct samples labels and losses\n",
    "            test_corr.append(correct.item()*100/len(testloader))\n",
    "            \n",
    "            test_loss.append(loss.item())\n",
    "                \n",
    "        print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "        labels = torch.Tensor(labels)\n",
    "        pred = torch.Tensor(pred)\n",
    "\n",
    "    print(\"Test Metrics: \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name, 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    end_time = time.time() - start_time    \n",
    "\n",
    "    # print training summary\n",
    "    print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "    print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "    print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_reserved()))\n",
    "\n",
    "    plot_loss(training_losses, test_loss) \n",
    "    plot_accuracy(training_accuracies, test_corr) \n",
    "\n",
    "    torch.save(model.state_dict(), model_dir + '/' + model_name + f'_fold_{fold}.pt')\n",
    "    df.to_csv('test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-bench",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2 # generates 7 new images + original image - per image, 4 * 8 = 32 images per batch\n",
    "\n",
    "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
    "    # Print\n",
    "    print(f'FOLD {fold+1}\\n')\n",
    "    \n",
    "    model_name = f'resnet50_frozen_w_aug_fold_{fold}' \n",
    "    \n",
    "    # Sample elements randomly from a given list of ids, no replacement.\n",
    "    train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "    test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "    \n",
    "    # Define data loaders for training and testing data in this fold\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                      dataset, \n",
    "                      batch_size=batch_size, sampler=train_subsampler, collate_fn=augmentor)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=augmentor)\n",
    "    \n",
    "    testloader_plain = torch.utils.data.DataLoader(\n",
    "                      dataset,\n",
    "                      batch_size=batch_size, sampler=test_subsampler, collate_fn=plain_transform)\n",
    "    \n",
    "    model = resnet50()\n",
    "\n",
    "    for params in model.parameters():\n",
    "        params.requires_grad = False\n",
    "\n",
    "    model.fc = nn.Linear(model.fc.in_features, 3)\n",
    "    \n",
    "    for params in model.fc.parameters():\n",
    "        params.requires_grad = True\n",
    "    \n",
    "    model = model.to(device)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print('\\nTraining the model')\n",
    "    b, test_b = 0, 0\n",
    "\n",
    "    training_losses = []\n",
    "    training_accuracies = []\n",
    "    test_loss = []\n",
    "    test_corr = []\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        e_start = time.time()\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_accuracy = 0.0\n",
    "        tst_corr = 0.0\n",
    "\n",
    "        for b, (X_train, y_train) in enumerate(trainloader):\n",
    "            X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y_pred = model(X_train)\n",
    "            \n",
    "            y_pred = y_pred.view(-1, n_classes)\n",
    "            \n",
    "            loss = criterion(y_pred, y_train)\n",
    "\n",
    "            predicted = torch.argmax(y_pred.data, dim=1).data\n",
    "            batch_corr = (predicted == y_train).sum()\n",
    "            running_accuracy += batch_corr\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            if b % int(len(trainloader)/batch_size) == 0:\n",
    "                print(f'Epoch: {epoch+1:2}  batch: {b+1:6} [{b+1:6}/{len(trainloader)}]  Loss: {loss.item():.6f}  Accuracy: {running_accuracy.item()*100/((batch_size * 8) * (b+1)):.6f}%')\n",
    "            \n",
    "        training_losses.append(loss.item())\n",
    "        training_accuracies.append(running_accuracy.item()*100/((batch_size * 8) * (b+1)))\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Training Accuracy: {training_accuracies[-1]:.6f}% | Training Loss: {training_losses[-1]:.6f}\")\n",
    "\n",
    "        model.eval()\n",
    "        b = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            labels = []\n",
    "            pred = []\n",
    "\n",
    "            new_y = 0.0\n",
    "\n",
    "            # perform test set evaluation batch wise\n",
    "            for b, (X, y) in enumerate(testloader):\n",
    "                b += 1\n",
    "                # set label to use CUDA if available\n",
    "                X, y = X.to(device), y.to(device)\n",
    "   \n",
    "                labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "                # perform forward pass\n",
    "                y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "                # get argmax of predicted values, which is our label\n",
    "                predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "                # append predicted label\n",
    "                pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "                # calculate loss\n",
    "                loss = criterion(y_val, y)\n",
    "\n",
    "                # increment correct with correcly predicted labels per batch\n",
    "                correct += (predicted == y).sum()\n",
    "\n",
    "            # append correct samples labels and losses\n",
    "            test_corr.append(correct.item()*100/len(testloader))\n",
    "            \n",
    "            test_loss.append(loss.item())\n",
    "                \n",
    "        print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "        labels = torch.Tensor(labels)\n",
    "        pred = torch.Tensor(pred)\n",
    "\n",
    "    print(\"Test Metrics (With test set augmentation): \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name, 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        labels = []\n",
    "        pred = []\n",
    "\n",
    "        new_y = 0.0\n",
    "\n",
    "        # perform test set evaluation batch wise\n",
    "        for b, (X, y) in enumerate(testloader_plain):\n",
    "            b += 1\n",
    "            # set label to use CUDA if available\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            labels.extend(y.view(-1).cpu().numpy())\n",
    "\n",
    "            # perform forward pass\n",
    "            y_val = model(X).view(-1, n_classes)\n",
    "\n",
    "            # get argmax of predicted values, which is our label\n",
    "            predicted = torch.argmax(y_val.data, dim=1).view(-1)\n",
    "\n",
    "            # append predicted label\n",
    "            pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(y_val, y)\n",
    "\n",
    "            # increment correct with correcly predicted labels per batch\n",
    "            correct += (predicted == y).sum()\n",
    "\n",
    "        # append correct samples labels and losses\n",
    "        test_corr.append(correct.item()*100/len(testloader_plain))\n",
    "\n",
    "        test_loss.append(loss.item())\n",
    "\n",
    "    print(f\"Test accuracy: {test_corr[-1]:.6f}% | Test Loss: {test_loss[-1]:.6f}\")\n",
    "\n",
    "    labels = torch.Tensor(labels)\n",
    "    pred = torch.Tensor(pred)\n",
    "    \n",
    "    print(\"Test Metrics (Without test set augmentation): \\n\")\n",
    "\n",
    "    plot_confusion_matrix(pred, labels, class_names)\n",
    "\n",
    "    a, p, p_avg, r, r_avg, f, f_avg = get_all_metrics(pred, labels)\n",
    "    \n",
    "    values = {'model': model_name + '_test_plain', 'accuracy': a, 'loss': test_loss[-1], 'precision_class_wise': p, 'precision_avg': p_avg, 'recall_class_wise': r, 'recall_avg': r_avg, 'f1_class_wise': f, 'f1_avg': f_avg}\n",
    "    df = df.append(values, ignore_index = True)\n",
    "    \n",
    "    print('Finished Training')\n",
    "\n",
    "    end_time = time.time() - start_time    \n",
    "\n",
    "    # print training summary\n",
    "    print(\"\\nTraining Duration {:.2f} minutes\".format(end_time/60))\n",
    "    print(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\n",
    "    print(\"GPU memory cached : {} kb\".format(torch.cuda.memory_reserved()))\n",
    "\n",
    "    plot_loss(training_losses, test_loss) \n",
    "    plot_accuracy(training_accuracies, test_corr) \n",
    "\n",
    "    torch.save(model.state_dict(), model_dir + '/' + model_name + f'_fold_{fold}.pt')\n",
    "    df.to_csv('test_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
